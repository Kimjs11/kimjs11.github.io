---
layout: posts
title:  "데이터셋 분류 및 네트워크 성능 지표(Accuracy, Recall, Precision, mAP)"
date:   2021-03-24 09:00:20 +0700
categories: [Machine Learning]
---
<link rel = "stylesheet" href ="/static/css/bootstrap.min.css">

--------------------------

기계학습에서 네트워크 모델, 분류를 수행할 때 그 성능 평가에 대해 이야기 해보도록 하겠습니다. 당연히 우리가 수치적으로 볼 수 있는 지표가 필요한 것은 당연한 사실입니다.
그리고 그 성능을 평가하기 위해선 데이터가 필요합니다. 머신러닝에서는 데이터를 Train, val, test로 나누어 평가를 합니다.<br/>

{% raw %} <img src="https://Kimjs11.github.io/img/데이터셋.png" alt=""> {% endraw %}
<br/>
Training data : Training 과정에서 모델을 학습시키는 데이터 <br/>
Validation data : Training 과정에서 중간 중간 평가를 합니다. 검증 데이터라고 부르기도 합니다. <br/>
test data : 최종적으로 모델 평가 지표를 위해 사용되는 데이터 <br/>
학습을 진행하여 epoch 가 진행될수록 일반적으로 val_loss(validation loss)는 감소되고 val_acc(validation accuracy)는 증가합니다.
<br/>
***epoch : 예를 들어 training data가 이미지 1,000장일 때 한번 1,000장을 훈련 시켰을 때 1epoch라 지칭***
이제 모든 훈련이 끝난 네트워크를 학습하지 않은 데이터를 입력하여 네트워크를 평가해야 합니다.<br/>
자세한 내용은 [머신러닝, 딥러닝에서 데이터를 나누는 이유](https://lsjsj92.tistory.com/545) 해당 블로그를 참고 <br/>

이렇게 분류된 데이터를 학습 및 테스트를 통해 성능 지표를 출력합니다.<br/>

모델을 평가하는 요소는 **모델이 내놓은 답**과 **실제 정답**의 관계로 정의를 내립니다. <br/>
모델이 내놓은 답은 Training data를 통해 학습된 모델이 학습하지 않은 데이터'처음 보는 데이터'를 보고 판단한 답이며 실제 정답은 사전에 Labeled data를 통해 학습된 데이터입니다.

1. Accuracy <br/>
: 일반적으로 하는 확률로 봅니다. <br/>
= 정답의 수 / 전체 데이터 수<br/>
2. Recall(재현율) <br/>
: 실제 정답 값 중 모델이 맞춘 정답의 수 <br/>
= Recall이 높으면 missed detection이 적은 것 <br/>
3. Precision(정밀도) <br/>
: 모델이 정답이라고 예측한 값 중 실제 정답의 수 <br/>
= Precision이 높으면 false alarm이 적은것 <br/>
4. F1 Score <br/>
: Recall 과 Precision의 조화평균 <br/>
= 2 x (Precision x Recall) / (Precision + Recall) <br/>
5. mAP(Mean Average Precision) <br/>
우선 딥러닝 객체 검출 알고리즘에서는 검출된 상자가 참일 가능성이 출력됩니다. 참의 기준이 되는 '임계값'(Threshold)의 설정에 따라 모델의 예측 결과가 참인지 거짓인지 판별되기 때문에 그에 따라
Precision, Recall 값이 변하게 된다. 여기서 Precision 만 골라내어 평균을 낸 것이 평균 정밀도(AP : Average Precision)입니다.<br/>
일반적으로 정확도(Precision)과 검출율(Recall)은 서로 반비례 관계를 가지기에 그래프를 통해 확인합니다.<br/>
{% raw %} <img src="https://Kimjs11.github.io/img/P-R curve.png" alt=""> {% endraw %}
<br/>
Precision - Recall curve를 통해 그린 그래프의 아래 면적을 통해 AP 값을 구하게 되며, 물체 클래스가 여러 개인 경우 각 클래스당 AP를 구한 다음에 모두 합한 다음 클래스의 개수로 나눠줌으로서 알고리즘의 성능을 평가합니다.
이것을 ***mAP(Mean Average Pricison)*** 이라고 합니다.
<br/>

## Reference <br/>
[1] https://sumniya.tistory.com/26?category=818582 <br/>
[2] http://hleecaster.com/ml-accuracy-recall-precision-f1/ <br/>

